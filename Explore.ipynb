{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense, Convolution2D, ELU, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.python.control_flow_ops = tf\n",
    "backend.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    model.save_weights(model_name+\".h5\", True)\n",
    "    with open(model_name+'.json', 'w') as outfile:\n",
    "        json.dump(model.to_json(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model_vgg16():\n",
    "    # vgg16\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    #Create input format\n",
    "    input = Input(name = 'image_input', shape=(224,224,3))\n",
    "\n",
    "    #Use the generated model \n",
    "    output_vgg16_conv = model_vgg16_conv(input)\n",
    "\n",
    "    # freeze vgg16 conv layers\n",
    "    for layer in model_vgg16_conv.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #model_vgg16_conv.summary()\n",
    "\n",
    "    # Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(256, activation='relu', name='fc1')(x)\n",
    "    x = Dense(256, activation='relu', name='fc2')(x)\n",
    "    x = Dense(1, activation='linear', name='predicton_steering')(x)\n",
    "\n",
    "    # Create model \n",
    "    return Model(input=input, output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model_nvidia():\n",
    "    # based on this paper:\n",
    "    # http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "    input = Input(shape=(80,160,3),name = 'image_input')\n",
    "\n",
    "    x=Convolution2D(24, 5, 5, border_mode=\"valid\", subsample=(2, 2), activation=\"relu\", name='conv1')(input)\n",
    "    x=Convolution2D(36, 5, 5, border_mode=\"valid\", subsample=(2, 2), activation=\"relu\", name='conv2')(x)\n",
    "    x=Convolution2D(48, 5, 5, border_mode=\"valid\", subsample=(2, 2), activation=\"relu\", name='conv3')(x)\n",
    "    x=Convolution2D(64, 3, 3, border_mode=\"valid\", subsample=(1, 1), activation=\"relu\", name='conv4')(x)\n",
    "    x=Convolution2D(64, 3, 3, border_mode=\"valid\", subsample=(1, 1), activation=\"relu\", name='conv5')(x)\n",
    "    x=Flatten(name='flatten')(x) \n",
    "    x=Dense(1164, activation=\"relu\", name='dense1')(x)\n",
    "    x=Dense(100, activation=\"relu\", name='dense2')(x)\n",
    "    x=Dense(50, activation=\"relu\", name='dense3')(x)\n",
    "    x=Dense(10, activation=\"relu\", name='dense4')(x)\n",
    "    x=Dense(1, name='dense5')(x)\n",
    "    \n",
    "    # Create model\n",
    "    return Model(input=input, output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model_commaai():\n",
    "    model = Sequential()\n",
    "    #model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "    #        input_shape=(ch, row, col),\n",
    "    #        output_shape=(ch, row, col)))\n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\", input_shape = (80,160,3)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image_input (InputLayer)         (None, 80, 160, 3)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Convolution2D)            (None, 38, 78, 24)    1824        image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Convolution2D)            (None, 17, 37, 36)    21636       conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3 (Convolution2D)            (None, 7, 17, 48)     43248       conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4 (Convolution2D)            (None, 5, 15, 64)     27712       conv3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv5 (Convolution2D)            (None, 3, 13, 64)     36928       conv4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 2496)          0           conv5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense1 (Dense)                   (None, 1164)          2906508     flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense2 (Dense)                   (None, 100)           116500      dense1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense3 (Dense)                   (None, 50)            5050        dense2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense4 (Dense)                   (None, 10)            510         dense3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense5 (Dense)                   (None, 1)             11          dense4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 3,159,927\n",
      "Trainable params: 3,159,927\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model=make_model_nvidia()\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv(base_path + '/data/udacity/data/' + 'driving_log.csv')\n",
    "log = log.drop(log[abs(log['steering']) < 0.1].index)\n",
    "#log['steering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data_log(base_path, csv_file_name, split=0.1, col_name='center', steer_mod=0.0, flip_th=None):\n",
    "    # read log file\n",
    "    log = pd.read_csv(base_path + '/' + csv_file_name)\n",
    "    \n",
    "    # drop rows base don flip_th\n",
    "    if flip_th is None:\n",
    "        flip = [0]*len(log)\n",
    "    else:\n",
    "        log = log.drop(log[abs(log['steering']) < flip_th].index)\n",
    "        flip = [1]*len(log)   \n",
    "    \n",
    "    # modify img file name column to contain the full path\n",
    "    log[col_name] = base_path + '/' + log[col_name].str.lstrip()\n",
    "    # extract img file names\n",
    "    img_names = log[col_name].tolist()\n",
    "    # extract angles\n",
    "    angles = log['steering']   \n",
    "    angles += steer_mod\n",
    "    \n",
    "    img_names_train, img_names_test, angles_train, angles_test = train_test_split(img_names, angles, test_size=split, random_state=42)\n",
    "    \n",
    "    return ( list(zip(img_names_train, angles_train, flip)), list(zip(img_names_test, angles_test, flip)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# center images\n",
    "train_data_list, test_data_list = preprocess_data_log(base_path + '/data/udacity/data', 'driving_log.csv')\n",
    "\n",
    "# left images\n",
    "train_data_list_l, test_data_list_l = preprocess_data_log(base_path + '/data/udacity/data', 'driving_log.csv',\n",
    "                                                          col_name='left', steer_mod=0.15)\n",
    "# right images\n",
    "train_data_list_r, test_data_list_r = preprocess_data_log(base_path + '/data/udacity/data', 'driving_log.csv',\n",
    "                                                          col_name='right', steer_mod=-0.15)\n",
    "\n",
    "# center images to be flipped\n",
    "train_data_list_f, test_data_list_f = preprocess_data_log(base_path + '/data/udacity/data', 'driving_log.csv',\n",
    "                                                      flip_th=0.1)\n",
    "\n",
    "# left images to be flipped\n",
    "train_data_list_l_f, test_data_list_l_f = preprocess_data_log(base_path + '/data/udacity/data', 'driving_log.csv',\n",
    "                                                          col_name='left', steer_mod=0.15, flip_th=0.1)\n",
    "\n",
    "# right images to be flipped\n",
    "train_data_list_r_f, test_data_list_r_f = preprocess_data_log(base_path + '/data/udacity/data', 'driving_log.csv',\n",
    "                                                          col_name='right', steer_mod=-0.15, flip_th=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_list = train_data_list +\\\n",
    "                    train_data_list_l +\\\n",
    "                    train_data_list_r +\\\n",
    "                    train_data_list_f +\\\n",
    "                    train_data_list_l_f +\\\n",
    "                    train_data_list_r_f\n",
    "\n",
    "\n",
    "test_data_list = test_data_list +\\\n",
    "                    test_data_list_l +\\\n",
    "                    test_data_list_r +\\\n",
    "                    test_data_list_f +\\\n",
    "                    test_data_list_l_f +\\\n",
    "                    test_data_list_r_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/carnd/CarND-Behavioral-Cloning-Project/data/udacity/data/IMG/center_2016_12_01_13_41_47_802.jpg',\n",
       " -0.26863309999999996,\n",
       " 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_list_f[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_model.compile(optimizer='adam', loss='mse')\n",
    "#my_model.compile(optimizer='adam', loss='mean_absolute_percentage_error', metrics=['accuracy'])\n",
    "#my_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_gen(name, data_list, out_img_size, batch_size):\n",
    "    # data_list is in this form: ['file_name', angle]\n",
    "    # out_img_size is a shape of the output image: (x, y, color)\n",
    "    \n",
    "    # create batch_size np arrays as placeholders for imgages and angles\n",
    "    X_train = np.empty((batch_size,) +  out_img_size, dtype = np.float32)\n",
    "    y_train = np.empty(batch_size, dtype = np.float32)\n",
    "    \n",
    "    # col & rows are reversed for cv2.resize\n",
    "    resize_shape = (out_img_size[1], out_img_size[0])\n",
    "    \n",
    "    while True:\n",
    "        # shuffle data\n",
    "        shuffle(data_list)\n",
    "        for offset in range(0, len(data_list), batch_size):\n",
    "            end = offset + batch_size\n",
    "            batch_subset = data_list[offset:end]\n",
    "            for i, _ in enumerate(batch_subset):\n",
    "                # load angle\n",
    "                y_train[i] = batch_subset[i][1]\n",
    "                \n",
    "                #load image\n",
    "                im = cv2.imread(batch_subset[i][0])\n",
    "                \n",
    "                # flip it if required\n",
    "                if batch_subset[i][2] == 1:\n",
    "                    im = cv2.flip(im, 1)\n",
    "                    y_train[i] *= -1.\n",
    "                    \n",
    "                # resize and norm\n",
    "                X_train[i] = (cv2.resize(im, resize_shape).astype(np.float32))/128. - 1.\n",
    "                #X_train[i] = np.expand_dims(im, axis=0)\n",
    "                \n",
    "                \n",
    "            batch_X, batch_y = X_train[:len(batch_subset)], y_train[:len(batch_subset)]\n",
    "            #print(name)\n",
    "            yield (batch_X, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#g=batch_gen(out[0:6], (160, 320, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27399"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(im, a) = next(g)\n",
    "len(train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3048"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(cv2.cvtColor((im[0]*255.+128.).astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
    "#im0 = cv2.resize(cv2.imread(train_data_list[0][0]), (224, 224))\n",
    "#plt.imshow(cv2.cvtColor(im0, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = batch_gen(\"train_gen\", train_data_list, (80, 160, 3), 128)\n",
    "test_gen = batch_gen(\"test_gen\", test_data_list, (80, 160, 3), 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      " 3072/27399 [==>...........................] - ETA: 37s - loss: 0.0059"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a7591aa868a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     max_q_size=1)\n\u001b[0m",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = my_model.fit_generator(\n",
    "    generator=train_gen, \n",
    "    validation_data=test_gen, \n",
    "    nb_val_samples=len(test_data_list), \n",
    "    samples_per_epoch=len(train_data_list), \n",
    "    nb_epoch=7,\n",
    "    max_q_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_model(my_model, 'nvidia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = batch_gen(\"train_gen\", train_data_list, (80, 160, 3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im, t = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#im[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im0 = (im[0]*128.+128.).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gen = batch_gen(\"train_gen\", train_data_list, (80, 160, 3), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im, s = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_model.predict(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
