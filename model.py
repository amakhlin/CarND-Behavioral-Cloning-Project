'''
This module trains a convolutional neural network to autonomously drive a car
in a simulator. This is a part of a submission for Project 3 of Udacity's self-driving car nanodegree.

	run it as follow:

	python model.py
'''

import numpy as np
import pandas as pd
import os
import cv2
from random import shuffle
import json

from keras.preprocessing import image
from keras.layers import Input, Flatten, Dense, Convolution2D, ELU, Dropout
from keras.models import Model, Sequential
from keras import backend
from keras import callbacks
from keras import optimizers
from keras.callbacks import ModelCheckpoint

from sklearn.model_selection import train_test_split

import tensorflow as tf


# Constants:

#add/subtract this amount of steering angle 
#to compensate for left/right camera views
STEERING_CORRECTION_LEFT_RIGHT = 0.25

# initial learning rate for the optimizer
LEARNING_RATE = 0.001
BATCH_SIZE = 64

# output image size
IMAGE_H_OUT	= 66
IMAGE_W_OUT	= 66

# crop top and buttom of the source image
CROP_TOP = 34
CROP_BOT = 20

DATA_LOG_PATH = '/data/udacity/data'
DATA_LOG_NAME = 'driving_log.csv'
									

def save_model(model, model_name):
	'''
	Save keras model as json
	'''
	with open(model_name+'.json', 'w') as outfile:
		json.dump(model.to_json(), outfile)


def make_model_nvidia():
	'''
	Create a convnet model
	This model architecture is based on the ideas in the Nvidea paper titled 
	"End to End Learning for Self-Driving Cars". This model has a shallower fully connected layer stack and expects
	a smaller image size: 66x66. The paper can be downloaded here:
		http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf
	'''

	model = Sequential()
	
	model.add(Convolution2D(24, 5, 5, border_mode="valid", subsample=(2, 2), activation="elu", input_shape = (IMAGE_H_OUT,IMAGE_W_OUT,3)))
	model.add(Convolution2D(36, 5, 5, border_mode="valid", subsample=(2, 2), activation="elu"))
	model.add(Convolution2D(48, 5, 5, border_mode="valid", subsample=(2, 2), activation="elu"))
	model.add(Convolution2D(64, 3, 3, border_mode="valid", subsample=(1, 1), activation="elu"))
	model.add(Convolution2D(64, 3, 3, border_mode="valid", subsample=(1, 1), activation="elu"))
	model.add(Flatten(name='flatten')) 
	model.add(Dense(100, activation="elu"))
	model.add(Dropout(0.5))
	model.add(Dense(50, activation="elu"))
	model.add(Dropout(0.5))
	model.add(Dense(10, activation="elu"))
	model.add(Dropout(0.5))
	model.add(Dense(1))

	# add an optimizer
	optimizer = optimizers.Adam(lr=LEARNING_RATE)

	# compile the model
	model.compile(optimizer, loss='mse')
	
	# Create model
	return model


def preprocess_data_log(base_path, csv_file_name, split=0.1, col_name='center', steer_aug=0.0):
	'''
	Parse the data log generated by the simulator for easy access

	Args:
		base_path (str)		: root of the dir where the log file is located
		csv_file_name (str)	: name of the log file
		split (float) 		: ratio of validation data to split off from the training data
		col_name (str)		: name of the column to process
		steer_aug (float)	: steering augmentation to add to the recorded steering angle,
								this is used to compensate for left and right camera views

	Returns:
		Two lists like so: training_set, validation_set
			each is composed of entries as follows (image_file_name, steering_angle)
			the file_name contains the full path that can be used by an image reading function
	'''

	# read log file using pandas lib
	log = pd.read_csv(base_path + '/' + csv_file_name)      
	
	# modify img file name column to contain the full path
	log[col_name] = base_path + '/' + log[col_name].str.lstrip()

	# extract img file names
	img_names = log[col_name].tolist()

	# extract angles
	angles = log['steering']  

	# augment steering angles 
	angles += steer_aug

	# split off a subset for validation
	img_names_train, img_names_test, angles_train, angles_test = train_test_split(img_names, angles, test_size=split, random_state=42)
	
	return ( list(zip(img_names_train, angles_train)), list(zip(img_names_test, angles_test)) )


def translate(img, tx, ty):
	'''
	Translate image by a given amount in X and Y

	Args:
		img (numpy.array)	: image
		tx (int)			: x shift in pixels
		ty (int)			: y shift in pixels

	Returns:
		Shifted image array (numpy.array)
	'''
	rows,cols,_ = img.shape

	M = np.float32([[1,0,tx],[0,1,ty]])
	return cv2.warpAffine(img,M,(cols,rows))


def random_shift(im, ang, max_x_shift = 50, max_y_shift = 25, pixels_per_steering_unit = 25./STEERING_CORRECTION_LEFT_RIGHT):
	'''
	Shift the image by a random amount in X and Y and compensate the steering angle for the shift in the X dir only

	Args:
		im (numpy.array)					: image
		ang (float)							: steering angle
		max_x_shift (int)					: maximum allowable shift in X in either dir
		max_y_shift (int)					: maximum allowable shift in Y either up or down
		pixels_per_steering_unit (float)	: steering correction factor in units of pixels/steering

	Returns:
		Translated image (numpy.array) and compensated angle
	'''
	
	xp = int(np.random.uniform(-1,1) * max_x_shift)
	yp = int(np.random.uniform(-1,1) * max_y_shift)
		
	ang = ang + xp / pixels_per_steering_unit
	
	return translate(im, xp, yp), ang


def batch_gen(data_list, batch_size, train_gen=True):
	'''
	Creates a generator which yields batches of training or validation data from data_list. Only batch_size worth of
	images are loaded into memory at a time. Perform random image shifting and flipping but only when train_gen is True

	Args:
		data_list			: a list of entries like this (img_file_name, steering_angle)
		barch_size (int)	: amount of data to yield at one time
		train_gen (bool)	: perform random data manipulation when True (ie for the training data set)

	Returns:
		numpy.array of images and steering angle values of length batch_size
	'''
	im_size = (IMAGE_H_IN, IMAGE_W_IN, 3)
	
	# create batch_size np arrays as placeholders for images and angles
	X_train = np.empty((batch_size,) +  im_size, dtype = np.float64)
	y_train = np.empty(batch_size, dtype = np.float64)
		
	while True:

		# shuffle data every time we go through the full data set
		shuffle(data_list)

		for offset in range(0, len(data_list), batch_size):

			# last batch may be smaller depending on the length of the data set
			end = offset + batch_size
			batch_subset = data_list[offset:end]

			# iterate over a batch
			for i, _ in enumerate(batch_subset):

				# load angle
				y_train[i] = batch_subset[i][1]
				
				#load image
				im = cv2.cvtColor(cv2.imread(batch_subset[i][0]), cv2.COLOR_BGR2RGB)
				
				# perform random image shifting & flipping only if this is a training set
				if train_gen:

					# flip images randomly with equal probability
					if np.random.choice([True, False]):
						im = cv2.flip(im, 1)
						y_train[i] *= -1.

					# Randomly translate the image in X & Y
					im, y_train[i] = random_shift(im, y_train[i])
					
				# crop - img[y: y + h, x: x + w]
				im = im[CROP_TOP:-CROP_BOT,:,:]
					
				# resize the image
				# convert it to float
				# and normalize pixel values to +/- 0.5
				X_train[i] = (cv2.resize(im, (IMAGE_W_OUT,IMAGE_H_OUT), interpolation=cv2.INTER_LINEAR).astype(np.float64))/255. - 0.5      
				
			batch_X, batch_y = X_train[:len(batch_subset)], y_train[:len(batch_subset)]

			yield (batch_X, batch_y)


if __name__ == '__main__':

	base_path = os.getcwd()

	# create the model
	my_model = make_model_nvidia()

	# save the model
	save_model(my_model, 'nvidia')


	# parse Udacity dataset

	# center images
	train_data_list, test_data_list = preprocess_data_log(base_path + DATA_LOG_PATH, DATA_LOG_NAME)

	# left images
	train_data_list_l, test_data_list_l = preprocess_data_log(base_path + DATA_LOG_PATH, DATA_LOG_NAME,
														  col_name='left', steer_mod=STEERING_CORRECTION_LEFT_RIGHT)
	# right images
	train_data_list_r, test_data_list_r = preprocess_data_log(base_path + DATA_LOG_PATH, DATA_LOG_NAME,
														  col_name='right', steer_mod=-STEERING_CORRECTION_LEFT_RIGHT)


	# combine data
	train_data_list = train_data_list + train_data_list_l + train_data_list_r
	test_data_list = test_data_list +test_data_list_l +test_data_list_r

	# create generators
	train_gen = batch_gen(train_data_list, BATCH_SIZE)
	test_gen = batch_gen(test_data_list, BATCH_SIZE, train_gen=False)

	# create a callback to save training weights after each epoch
	checkpoint_path="nvidia-{epoch:02d}.h5"
	checkpoint = ModelCheckpoint(checkpoint_path, verbose=0, save_best_only=False, save_weights_only=True, mode='auto')

	# train the model
	history = my_model.fit_generator(
		generator=train_gen, 
		validation_data=test_gen, 
		nb_val_samples=len(test_data_list), 
		samples_per_epoch=len(train_data_list), 
		nb_epoch=20,
		max_q_size=2,
		callbacks=[checkpoint])

